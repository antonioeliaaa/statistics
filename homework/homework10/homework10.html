<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="color-scheme" content="light" />
  <title>Homework 10 — Poisson Counting Process Simulation</title>

  <!-- Global stylesheet -->
  <link rel="stylesheet" href="../../style.css" />

  <!-- MathJax for LaTeX rendering -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>

  <header>
    <h1>Statistics — Antonio Elia</h1>
    <p>Homework 10 — Student ID: 2253126</p>
  </header>

  <main>
    <section>

      <h2>1. Problem Description</h2>
      <p>
        In this homework we simulate a <strong>counting process</strong> over a time interval \([0, T]\) (for example \(T = 1\)),
        where events (“successes”) occur independently and uniformly in time at a constant average rate \(\lambda\).
      </p>
      <p>
        The interval is approximated by dividing \([0, T]\) into \(n\) small subintervals and, in each subinterval,
        generating an event with probability approximately \(\lambda \Delta t\), where \(\Delta t = T/n\). 
        For \(T = 1\) this corresponds to a probability \(\lambda / n\) per subinterval, as specified in the assignment.
      </p>
      <p>
        The aims are:
      </p>
      <ul>
        <li>to simulate the resulting counting process numerically,</li>
        <li>to identify what <strong>stochastic process</strong> it approximates,</li>
        <li>to discuss its theoretical properties,</li>
        <li>to interpret the meaning of the rate parameter \(\lambda\).</li>
      </ul>

      <h2>2. Discrete Approximation Scheme</h2>
      <p>
        Consider the time interval \([0, T]\), divided into \(n\) subintervals of equal length:
      </p>
      <p>\[
        \Delta t = \frac{T}{n}.
      \]</p>
      <p>
        On each subinterval we generate at most one event, independently of the others. 
        The idea is:
      </p>
      <ul>
        <li>for the \(k\)-th subinterval, we define a Bernoulli random variable:
          \[
            Y_k =
            \begin{cases}
              1, & \text{if an event occurs in subinterval } k, \\
              0, & \text{otherwise},
            \end{cases}
          \]
        </li>
        <li>with probability
          \[
            \mathbb{P}(Y_k = 1) \approx \lambda \Delta t.
          \]
          For \(T = 1\) and \(\Delta t = 1/n\), this is exactly \(\lambda / n\), as in the homework statement.</li>
      </ul>
      <p>
        The (discrete) counting process at time \(t_j = j\Delta t\) is:
      </p>
      <p>\[
        N_n(t_j) = \sum_{k=1}^{j} Y_k, \quad j = 0, 1, \dots, n.
      \]</p>
      <p>
        In particular, the total number of events over \([0, T]\) is:
      </p>
      <p>\[
        N_n(T) = \sum_{k=1}^{n} Y_k \sim \operatorname{Binomial}\!\left(n, \lambda\Delta t\right)
        = \operatorname{Binomial}\!\left(n, \frac{\lambda T}{n}\right).
      \]</p>
      <p>
        As \(n \to \infty\) (and thus \(\Delta t \to 0\)), the Binomial distribution converges to a Poisson distribution:
      </p>
      <p>\[
        N_n(T) \xrightarrow[n\to\infty]{d} \operatorname{Poisson}(\lambda T).
      \]</p>

      <h2>3. Identification of the Limit Process</h2>
      <p>
        The limiting object of this construction is the <strong>Poisson counting process</strong> with rate \(\lambda\),
        usually denoted by \((N(t))_{t \ge 0}\), defined by the properties:
      </p>
      <ul>
        <li>\(N(0) = 0\) almost surely;</li>
        <li>\(N(t)\) has <strong>independent increments</strong>:
          for any disjoint time intervals, increments are independent random variables;</li>
        <li>\(N(t)\) has <strong>stationary increments</strong>:
          the distribution of \(N(t+s) - N(s)\) depends only on the length \(t\), not on \(s\);</li>
        <li>
          for each \(t \ge 0\),
          \[
            N(t) \sim \operatorname{Poisson}(\lambda t);
          \]
        </li>
        <li>paths are almost surely non-decreasing, integer-valued, right-continuous step functions.</li>
      </ul>
      <p>
        Our discrete simulation with \(n\) subintervals and Bernoulli events is a <em>time-discretised approximation</em> of this process.
        As \(n\) increases:
      </p>
      <ul>
        <li>the distribution of \(N_n(T)\) approaches \(\operatorname{Poisson}(\lambda T)\);</li>
        <li>the sample paths of \(N_n(t)\) converge (in a suitable sense) to the typical sample paths of a Poisson process.</li>
      </ul>

      <h2>4. Theoretical Properties of the Poisson Counting Process</h2>

      <h3>4.1 Distribution of Counts</h3>
      <p>
        For a Poisson process \((N(t))_{t\ge0}\) with rate \(\lambda\):
      </p>
      <p>\[
        N(t) \sim \operatorname{Poisson}(\lambda t),
      \]</p>
      <p>
        i.e.:
      </p>
      <p>\[
        \mathbb{P}(N(t) = k)
        = e^{-\lambda t} \frac{(\lambda t)^k}{k!},
        \quad k = 0, 1, 2, \dots
      \]</p>
      <p>
        The mean and variance of \(N(t)\) are:
      </p>
      <p>\[
        \mathbb{E}[N(t)] = \lambda t,
        \qquad
        \operatorname{Var}(N(t)) = \lambda t.
      \]</p>

      <h3>4.2 Independent and Stationary Increments</h3>
      <p>
        For \(0 \le t_0 &lt; t_1 &lt; \dots &lt; t_k\), the increments:
      </p>
      <p>\[
        N(t_1) - N(t_0),\,
        N(t_2) - N(t_1),\, \dots,\,
        N(t_k) - N(t_{k-1})
      \]</p>
      <p>
        are independent random variables and:
      </p>
      <p>\[
        N(t_j) - N(t_{j-1}) \sim \operatorname{Poisson}(\lambda (t_j - t_{j-1})).
      \]</p>
      <p>
        This reflects the idea of events occurring in time in a “memoryless” way with constant average rate.

      <h3>4.3 Interarrival Times</h3>
      <p>
        Let \(T_1\) be the time of the first event, and \(T_2\) the time between the first and second event, etc. 
        Then:
      </p>
      <p>\[
        T_1, T_2, \dots \text{ are i.i.d. } \sim \operatorname{Exponential}(\lambda)
      \]</p>
      <p>
        with density:
      </p>
      <p>\[
        f_{T}(t) = \lambda e^{-\lambda t}, \quad t \ge 0.
      \]</p>
      <p>
        Therefore, the Poisson process can also be viewed as the process obtained by summing independent exponential waiting times.

      <h2>5. Interpretation of the Rate Parameter \(\lambda\)</h2>
      <p>
        The parameter \(\lambda &gt; 0\) is called the <strong>rate</strong> of the process. It has several equivalent interpretations:
      </p>
      <ul>
        <li>Average number of events per unit time:
          \[
            \mathbb{E}[N(1)] = \lambda.
          \]
          For a generic interval \([0, t]\), the expected number of events is \(\lambda t\).</li>
        <li>
          Reciprocal of the mean interarrival time:
          since \(T_1 \sim \operatorname{Exponential}(\lambda)\),
          \[
            \mathbb{E}[T_1] = \frac{1}{\lambda},
          \]
          so the typical waiting time between successive events is approximately \(1/\lambda\).</li>
        <li>
          In the discrete approximation, the rate \(\lambda\) is the limit:
          \[
            \lambda = \lim_{\Delta t \to 0} \frac{\mathbb{P}(\text{one event in an interval of length } \Delta t)}{\Delta t}.
          \]
        </li>
      </ul>
      <p>
        Intuitively, a larger \(\lambda\) corresponds to a more “crowded” process (events happen more frequently), while a smaller
        \(\lambda\) corresponds to a sparser process.

      <h2>6. Interactive Simulation</h2>
      <p>
        The following panel simulates the counting process on \([0, T]\) by:
      </p>
      <ul>
        <li>dividing the interval into \(n\) subintervals of length \(\Delta t = T/n\);</li>
        <li>in each subinterval, generating an event with probability \(p \approx \lambda \Delta t\);</li>
        <li>constructing the sample path \(N_n(t_j)\) for one trajectory;</li>
        <li>repeating the experiment for many trials to build the empirical distribution of \(N_n(T)\);</li>
        <li>comparing the histogram of \(N_n(T)\) with the theoretical Poisson\((\lambda T)\) distribution.</li>
      </ul>

      <div class="controls">
        <p>
          <label for="lambda"><strong>Rate (λ):</strong></label>
          <input id="lambda" type="number" min="0" step="0.1" value="5" />
        </p>

        <p>
          <label for="T"><strong>Time horizon (T):</strong></label>
          <input id="T" type="number" min="0.1" step="0.1" value="1" />
        </p>

        <p>
          <label for="n"><strong>Subintervals (n):</strong></label>
          <input id="n" type="number" min="10" step="10" value="5000" />
        </p>

        <p>
          <label for="trials"><strong>Number of trajectories:</strong></label>
          <input id="trials" type="number" min="1" value="2000" />
        </p>

        <button id="simulateButton">Simulate</button>
      </div>

      <p id="p-info"></p>

      <h3>6.1 Sample Path of the Counting Process</h3>
      <p>
        The chart below shows one realisation of the counting process \(N_n(t)\) on \([0, T]\). 
        It is a non-decreasing step function starting at 0: each jump corresponds to an event.
      </p>

      <canvas id="pathChart"></canvas>

      <h3>6.2 Distribution of the Total Number of Events</h3>
      <p>
        The next chart compares:
      </p>
      <ul>
        <li>the empirical distribution of the total number of events \(N_n(T)\) over all simulated trajectories (bars),</li>
        <li>the theoretical Poisson\((\lambda T)\) probabilities (line).</li>
      </ul>
      <p>
        As \(n\) and the number of trajectories increase, the empirical distribution converges to the Poisson distribution.
      </p>

      <canvas id="histChart"></canvas>

      <a class="button" href="../../index.html">⬅ Back to Home</a>

    </section>
  </main>

  <footer>
    <small>© 2025 — Homework 10 by Antonio Elia (2253126)</small>
  </footer>

  <!-- Chart.js for plots -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <script>
    const lambdaInput = document.getElementById('lambda');
    const TInput = document.getElementById('T');
    const nInput = document.getElementById('n');
    const trialsInput = document.getElementById('trials');
    const simulateButton = document.getElementById('simulateButton');
    const pInfo = document.getElementById('p-info');

    const pathCanvas = document.getElementById('pathChart');
    const histCanvas = document.getElementById('histChart');

    let pathChart = null;
    let histChart = null;

    function simulateCountingProcess(lambda, T, n, trials) {
      const dt = T / n;
      const p = Math.min(lambda * dt, 1); // event probability per subinterval
      const counts = new Array(trials);
      const timeGrid = [];
      const path = [];

      for (let j = 0; j <= n; j++) {
        timeGrid.push(j * dt);
      }

      // simulate one sample path for plotting
      let N = 0;
      path.push(0);
      for (let j = 1; j <= n; j++) {
        if (Math.random() < p) {
          N++;
        }
        path.push(N);
      }

      // simulate many trajectories for histogram
      for (let t = 0; t < trials; t++) {
        let count = 0;
        for (let j = 0; j < n; j++) {
          if (Math.random() < p) {
            count++;
          }
        }
        counts[t] = count;
      }

      return { dt, p, timeGrid, path, counts };
    }

    function poissonPMF(k, mu) {
      if (k < 0) return 0;
      // compute e^{-mu} mu^k / k! using recurrence for stability
      let res = Math.exp(-mu);
      let term = res; // k=0 term
      if (k === 0) return term;
      for (let i = 1; i <= k; i++) {
        term *= mu / i;
      }
      return term;
    }

    function buildHistogram(counts, mu) {
      const maxObserved = counts.reduce((a, b) => Math.max(a, b), 0);
      const suggestedMax = Math.ceil(mu + 4 * Math.sqrt(mu));
      const maxK = Math.max(0, Math.min(Math.max(maxObserved, suggestedMax), 40));

      const freq = new Array(maxK + 1).fill(0);
      counts.forEach(c => {
        if (c <= maxK) {
          freq[c]++;
        }
      });

      const total = counts.length;
      const empirical = freq.map(f => f / total);
      const theoretical = [];
      for (let k = 0; k <= maxK; k++) {
        theoretical.push(poissonPMF(k, mu));
      }

      const labels = [];
      for (let k = 0; k <= maxK; k++) labels.push(k.toString());

      return { labels, empirical, theoretical };
    }

    function updatePathChart(timeGrid, path) {
      if (pathChart) {
        pathChart.destroy();
      }

      pathChart = new Chart(pathCanvas, {
        type: 'line',
        data: {
          labels: timeGrid,
          datasets: [
            {
              label: 'Sample path N(t)',
              data: path,
              stepped: true,
              fill: false
            }
          ]
        },
        options: {
          responsive: true,
          scales: {
            x: {
              title: {
                display: true,
                text: 'Time t'
              }
            },
            y: {
              title: {
                display: true,
                text: 'N(t)'
              },
              beginAtZero: true
            }
          }
        }
      });
    }

    function updateHistChart(labels, empirical, theoretical) {
      if (histChart) {
        histChart.destroy();
      }

      histChart = new Chart(histCanvas, {
        type: 'bar',
        data: {
          labels: labels,
          datasets: [
            {
              label: 'Empirical P(N(T) = k)',
              data: empirical
            },
            {
              type: 'line',
              label: 'Poisson(λT) theoretical',
              data: theoretical
            }
          ]
        },
        options: {
          responsive: true,
          scales: {
            x: {
              title: {
                display: true,
                text: 'k = number of events in [0, T]'
              }
            },
            y: {
              title: {
                display: true,
                text: 'Probability'
              },
              beginAtZero: true
            }
          }
        }
      });
    }

    function runSimulation() {
      const lambda = parseFloat(lambdaInput.value);
      const T = parseFloat(TInput.value);
      const n = parseInt(nInput.value, 10);
      const trials = parseInt(trialsInput.value, 10);

      if (!Number.isFinite(lambda) || lambda < 0) {
        alert('λ must be a non-negative number.');
        return;
      }
      if (!Number.isFinite(T) || T <= 0) {
        alert('T must be a positive number.');
        return;
      }
      if (!Number.isFinite(n) || n <= 0) {
        alert('n must be a positive integer.');
        return;
      }
      if (!Number.isFinite(trials) || trials <= 0) {
        alert('Number of trajectories must be positive.');
        return;
      }

      const { dt, p, timeGrid, path, counts } = simulateCountingProcess(lambda, T, n, trials);
      const mu = lambda * T;
      const { labels, empirical, theoretical } = buildHistogram(counts, mu);

      pInfo.textContent =
        'Δt = ' + dt.toExponential(3) +
        ',  event probability per subinterval ≈ λΔt = ' + p.toFixed(5) +
        ',  expected count μ = λT = ' + mu.toFixed(2);

      updatePathChart(timeGrid, path);
      updateHistChart(labels, empirical, theoretical);
    }

    simulateButton.addEventListener('click', runSimulation);

    // initial run
    runSimulation();
  </script>

</body>
</html>
