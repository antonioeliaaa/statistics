<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="color-scheme" content="light" />
  <title>Homework 9 — Interpretations of Probability & Axiomatic Approach</title>

  <!-- Global stylesheet -->
  <link rel="stylesheet" href="../../style.css" />

  <!-- MathJax for LaTeX rendering -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>

  <header>
    <h1>Statistics — Antonio Elia</h1>
    <p>Homework 9 — Student ID: 2253126</p>
  </header>

  <main>
    <section>

      <h2>1. Goal of the Homework</h2>
      <p>
        In this homework we:
      </p>
      <ul>
        <li>review the main <strong>interpretations of probability</strong> (classical, frequentist, Bayesian, geometric, etc.);</li>
        <li>explain how the <strong>axiomatic approach</strong> reconciles and clarifies conceptual inconsistencies between them;</li>
        <li>describe the relationship between <strong>probability theory and measure theory</strong> (σ–algebras, probability measures, measurable functions, random variables);</li>
        <li>derive, using only the axioms of probability, the <strong>subadditivity property</strong> and the <strong>inclusion–exclusion principle</strong>.</li>
      </ul>

      <h2>2. Main Interpretations of Probability</h2>

      <h3>2.1 Classical (Laplace) Interpretation</h3>
      <p>
        The classical view (Laplace) defines probability for a finite sample space with <em>equally likely</em> outcomes:
      </p>
      <p>\[
        P(A) = \frac{\text{number of favourable outcomes}}{\text{number of possible outcomes}}
      \]</p>
      <p>
        This works well for symmetric settings (ideal dice, coins, cards), but it relies on:
      </p>
      <ul>
        <li>an a priori symmetry assumption (equally likely outcomes);</li>
        <li>finite sample spaces;</li>
        <li>ambiguities when different symmetry assumptions are possible (e.g. Bertrand paradox).</li>
      </ul>

      <h3>2.2 Frequentist Interpretation</h3>
      <p>
        In the frequentist view, the probability of an event \(A\) is the long-run <strong>relative frequency</strong> of \(A\) in repeated identical experiments:
      </p>
      <p>\[
        P(A) = \lim_{n \to \infty} \frac{N_n(A)}{n},
      \]</p>
      <p>
        where \(N_n(A)\) is the number of times \(A\) occurs in \(n\) trials. The Law of Large Numbers gives a mathematical justification:
        relative frequencies converge (under conditions) towards a stable value.
      </p>
      <p>
        Conceptual issues:
      </p>
      <ul>
        <li>depends on an idealised infinite sequence of repetitions;</li>
        <li>probability of <em>single events</em> (e.g. tomorrow it will rain) is not directly defined;</li>
        <li>no natural place for prior information or degree of belief.</li>
      </ul>

      <h3>2.3 Bayesian Interpretation</h3>
      <p>
        The Bayesian interpretation treats probability as a <strong>degree of belief</strong> of a rational agent. For an event \(A\),
        \(P(A)\) quantifies subjective uncertainty, constrained by coherence (no Dutch books).
      </p>
      <p>
        The key update rule is Bayes’ theorem:
      </p>
      <p>\[
        P(\theta \mid \text{data}) =
        \frac{P(\text{data} \mid \theta)\,P(\theta)}{P(\text{data})},
      \]</p>
      <p>
        where \(P(\theta)\) is the prior, \(P(\text{data} \mid \theta)\) the likelihood, and \(P(\theta \mid \text{data})\) the posterior.
      </p>
      <p>
        Strengths:
      </p>
      <ul>
        <li>probabilities for single events are allowed and meaningful;</li>
        <li>incorporates prior knowledge and learning from data.</li>
      </ul>
      <p>
        Criticisms:
      </p>
      <ul>
        <li>subjectivity in the choice of priors;</li>
        <li>debates about “objective” vs “subjective” Bayesianism.</li>
      </ul>

      <h3>2.4 Geometric and Other Interpretations</h3>
      <p>
        In the geometric interpretation, probabilities are ratios of lengths, areas or volumes. For example, if we choose a
        point uniformly at random on a segment:
      </p>
      <p>\[
        P(A) = \frac{\text{length of favourable subset}}{\text{length of total segment}}.
      \]</p>
      <p>
        This extends the classical finite–outcome idea to continuous spaces. However, it also suffers from ambiguities when
        the notion of “uniform” depends on the parameterisation (again, Bertrand-type paradoxes).
      </p>
      <p>
        Other views (propensity interpretation, logical interpretation, etc.) emphasise different philosophical aspects
        (physical tendencies, logical degrees of support), but as soon as we do rigorous calculations we usually fall back
        to the same mathematical core: the axiomatic framework.

      <h2>3. Axiomatic Approach and Resolution of Inconsistencies</h2>
      <p>
        Kolmogorov’s axioms take an <strong>abstract</strong> point of view. A probability space is a triple
        \((\Omega, \mathcal{F}, P)\) where:
      </p>
      <ul>
        <li>\(\Omega\) is the sample space (set of possible outcomes),</li>
        <li>\(\mathcal{F}\) is a σ–algebra of subsets of \(\Omega\) (events),</li>
        <li>\(P : \mathcal{F} \to [0,1]\) is a function satisfying:
          <ul>
            <li>\(P(\Omega) = 1\),</li>
            <li>\(P(A) \ge 0\) for all \(A \in \mathcal{F}\),</li>
            <li>for any countable collection of pairwise disjoint events \((A_i)_{i\ge 1}\),
              \[
                P\Bigl(\bigcup_{i=1}^\infty A_i\Bigr)
                = \sum_{i=1}^\infty P(A_i)
              \]
              (countable additivity).</li>
          </ul>
        </li>
      </ul>
      <p>
        Crucial point: the axioms do <strong>not</strong> choose one specific philosophical interpretation. Instead,
        they provide a common <em>mathematical</em> language:
      </p>
      <ul>
        <li>classical probability: \(\Omega\) finite, \(\mathcal{F} = \mathcal{P}(\Omega)\), and \(P\) uniform on outcomes;</li>
        <li>frequentist view: \(P\) is interpreted as limit of frequencies, but the mathematical object is still a measure
          over \((\Omega, \mathcal{F})\);</li>
        <li>Bayesian view: \(P\) encodes degrees of belief, but must still obey the same axioms;</li>
        <li>geometric view: \(P(A) = \frac{\mu(A)}{\mu(\Omega)}\) for some underlying measure \(\mu\) (length, area, volume).</li>
      </ul>
      <p>
        Inconsistencies (like different answers depending on the choice of “uniform” parameterisation) are revealed as
        <strong>different choices of sample space, σ–algebra and measure</strong>, not contradictions of the theory.
        Once we specify clearly:
      </p>
      <ul>
        <li>what \(\Omega\) is,</li>
        <li>which sets are measurable (σ–algebra \(\mathcal{F}\)),</li>
        <li>which probability measure \(P\) we use,</li>
      </ul>
      <p>
        the ambiguities disappear. The axioms act as a neutral “referee” for all interpretations.

      <h2>4. Probability Theory and Measure Theory</h2>

      <h3>4.1 σ–Algebras</h3>
      <p>
        A <strong>σ–algebra</strong> \(\mathcal{F}\) on a set \(\Omega\) is a collection of subsets of \(\Omega\) such that:
      </p>
      <ul>
        <li>\(\Omega \in \mathcal{F}\),</li>
        <li>if \(A \in \mathcal{F}\) then \(A^c \in \mathcal{F}\),</li>
        <li>if \((A_i)_{i\ge 1} \subseteq \mathcal{F}\), then \(\bigcup_{i=1}^\infty A_i \in \mathcal{F}\).</li>
      </ul>
      <p>
        Elements of \(\mathcal{F}\) are the <strong>events</strong> to which we can assign probabilities.

      <h3>4.2 Probability Measures</h3>
      <p>
        A <strong>probability measure</strong> is a function \(P : \mathcal{F} \to [0,1]\) satisfying the axioms above. It is a
        special case of a measure with total mass \(1\). All standard properties (monotonicity, continuity, subadditivity,
        etc.) come from these axioms.

      <h3>4.3 Measurable Functions and Random Variables</h3>
      <p>
        In measure theory, a function \(X : \Omega \to \mathbb{R}\) is <strong>measurable</strong> if
        \(\{ \omega \in \Omega : X(\omega) \le x \} \in \mathcal{F}\) for all real \(x\). In probability:
      </p>
      <p>
        a measurable function \(X\) from \((\Omega, \mathcal{F}, P)\) to \((\mathbb{R}, \mathcal{B}(\mathbb{R}))\) is exactly a
        <strong>random variable</strong>.
      </p>
      <p>
        Its distribution is the pushforward measure:
      </p>
      <p>\[
        P_X(B) = P(\{\omega \in \Omega : X(\omega) \in B\}),
        \quad B \in \mathcal{B}(\mathbb{R}).
      \]</p>
      <p>
        Expectation is defined via the Lebesgue integral:
      </p>
      <p>\[
        \mathbb{E}[X] = \int_\Omega X(\omega)\, dP(\omega)
        = \int_{\mathbb{R}} x \, dP_X(x).
      \]</p>
      <p>
        In this way, probability theory becomes a special case of measure theory: random variables are measurable functions,
        probabilities are measures, expectations are integrals, and many advanced results (e.g. convergence theorems) are
        inherited directly from measure theory.

      <h2>5. Subadditivity from the Axioms</h2>
      <p>
        A key property of any probability measure is <strong>subadditivity</strong>:
      </p>
      <p>\[
        P\Bigl(\bigcup_{i=1}^\infty A_i\Bigr)
        \le \sum_{i=1}^\infty P(A_i).
      \]</p>
      <p>
        Derivation:
      </p>
      <ol>
        <li>From the events \(A_i\), construct a sequence of <strong>disjoint</strong> events \((B_i)_{i\ge 1}\):
          \[
            B_1 = A_1, \quad
            B_2 = A_2 \setminus A_1, \quad
            B_3 = A_3 \setminus (A_1 \cup A_2), \dots
          \]
          so that:
          \[
            B_i \subseteq A_i, \quad B_i \cap B_j = \emptyset \text{ for } i \ne j.
          \]</li>
        <li>By construction:
          \[
            \bigcup_{i=1}^\infty A_i = \bigcup_{i=1}^\infty B_i.
          \]</li>
        <li>By countable additivity on disjoint sets:
          \[
            P\Bigl(\bigcup_{i=1}^\infty A_i\Bigr)
            = P\Bigl(\bigcup_{i=1}^\infty B_i\Bigr)
            = \sum_{i=1}^\infty P(B_i).
          \]</li>
        <li>Since \(B_i \subseteq A_i\), by monotonicity \(P(B_i) \le P(A_i)\) for each \(i\). Therefore:
          \[
            \sum_{i=1}^\infty P(B_i)
            \le \sum_{i=1}^\infty P(A_i).
          \]</li>
      </ol>
      <p>
        Combining the steps:
      </p>
      <p>\[
        P\Bigl(\bigcup_{i=1}^\infty A_i\Bigr)
        = \sum_{i=1}^\infty P(B_i)
        \le \sum_{i=1}^\infty P(A_i).
      \]</p>
      <p>
        This shows that subadditivity is a direct consequence of the axioms (countable additivity + monotonicity).

      <h2>6. Inclusion–Exclusion Principle</h2>

      <h3>6.1 Case of Two Events</h3>
      <p>
        For two events \(A, B \in \mathcal{F}\), we want to express \(P(A \cup B)\) in terms of \(P(A)\), \(P(B)\), and the
        intersection \(P(A \cap B)\).
      </p>
      <p>
        Decompose the union into disjoint parts:
      </p>
      <p>\[
        A \cup B = A \,\cup\, (B \setminus A).
      \]</p>
      <p>
        The sets \(A\) and \(B \setminus A\) are disjoint. By additivity:
      </p>
      <p>\[
        P(A \cup B) = P(A) + P(B \setminus A).
      \]</p>
      <p>
        But:
      </p>
      <p>\[
        B = (B \setminus A) \cup (A \cap B),
      \]</p>
      <p>
        with disjoint union, so:
      </p>
      <p>\[
        P(B) = P(B \setminus A) + P(A \cap B)
        \quad \Rightarrow \quad
        P(B \setminus A) = P(B) - P(A \cap B).
      \]</p>
      <p>
        Substituting:
      </p>
      <p>\[
        P(A \cup B) = P(A) + P(B) - P(A \cap B).
      \]</p>
      <p>
        This is the <strong>inclusion–exclusion formula</strong> for two events.

      <h3>6.2 General Finite Inclusion–Exclusion</h3>
      <p>
        For a finite family of events \(A_1, \dots, A_n\), the inclusion–exclusion principle generalises to:
      </p>
      <p>\[
        P\Bigl(\bigcup_{i=1}^n A_i\Bigr)
        = \sum_{i} P(A_i)
        - \sum_{i<j} P(A_i \cap A_j)
        + \sum_{i<j<k} P(A_i \cap A_j \cap A_k)
        - \cdots
        + (-1)^{n+1} P(A_1 \cap \dots \cap A_n).
      \]</p>
      <p>
        Intuitively:
      </p>
      <ul>
        <li>we first <strong>add</strong> all single probabilities \(P(A_i)\);</li>
        <li>we then <strong>subtract</strong> all pairwise intersections (because they were counted twice);</li>
        <li>we then <strong>add</strong> triple intersections (subtracted one time too many), and so on,</li>
        <li>alternating signs to avoid overcounting.</li>
      </ul>
      <p>
        This formula can be derived rigorously from the axioms by partitioning \(\Omega\) into disjoint regions associated
        with all possible patterns of membership in the \(A_i\), and then summing the probabilities of the regions that
        belong to at least one \(A_i\).

      <h2>7. Conclusions</h2>
      <p>
        In this homework we have:
      </p>
      <ul>
        <li>reviewed multiple interpretations of probability (classical, frequentist, Bayesian, geometric) and their
          conceptual strengths and weaknesses;</li>
        <li>seen how Kolmogorov’s <strong>axiomatic framework</strong> acts as a unifying mathematical theory that all
          interpretations must obey;</li>
        <li>connected probability with <strong>measure theory</strong>: σ–algebras define measurable events, probability
          measures assign them mass, and random variables are measurable functions;</li>
        <li>derived, starting only from the axioms, two fundamental properties:
          <strong>subadditivity</strong> and the <strong>inclusion–exclusion principle</strong>.</li>
      </ul>
      <p>
        This shows that many “philosophical” debates about probability live on top of a single rigorous mathematical
        infrastructure, which is based on measure theory and a small set of axioms from which the main properties of
        probabilities can be deduced systematically.
      </p>

      <a class="button" href="../../index.html">⬅ Back to Home</a>

    </section>
  </main>

  <footer>
    <small>© 2025 — Homework 9 by Antonio Elia (2253126)</small>
  </footer>

</body>
</html>
